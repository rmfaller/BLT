
Job:
  descriptions (load gen and target(s))
  number of threads and thread group size (number of threads to spawn at a time) and thread interval (time to wait between thread spawns)
  number of connections and to keep alive for duration or not
  list workload(s) and number of iterations
  following can be overridden by workload and/or task
    endpoint + port
    credentials
    lowerbounds and upperbounds (for user.xxx)

Workloads:
  task(s) + SLA per task
  state to be shared between tasks
  option:
    endpoint + port
    credentials

Tasks:
  API calls
    request type: POST, GET, PATCH, ....
    Headers
    url-endpoint
    url-payload
    data-payload
  option:
    endpoint + port
    credentials

shared values:
  randomvalue
  tokenid
  threadid
  increment

Features to add:
All json stored in DS
ingest cURL commands
tasks can read from files tasks
tasks can be created from existing logs based on usage profile
tasks support LDAP

Process to clean up, example:
Run blt to create users and then using the same thread count and iterations run blt again to delete entries
Same with authentication into AM
Use same job
set thresholds to zero to build cleanup strings for logout, delete entries
file or directory per thread 
add $BLT-EPOCHTIME for unique data

Code cuts:
